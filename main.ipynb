{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d45b85",
   "metadata": {
    "papermill": {
     "duration": 0.004317,
     "end_time": "2025-09-04T10:55:29.023726",
     "exception": false,
     "start_time": "2025-09-04T10:55:29.019409",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# EDA and undertanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d33ee22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T10:55:29.031789Z",
     "iopub.status.busy": "2025-09-04T10:55:29.031468Z",
     "iopub.status.idle": "2025-09-04T10:55:35.839365Z",
     "shell.execute_reply": "2025-09-04T10:55:35.838418Z"
    },
    "papermill": {
     "duration": 6.813946,
     "end_time": "2025-09-04T10:55:35.841178",
     "exception": false,
     "start_time": "2025-09-04T10:55:29.027232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf\r\n",
      "  Downloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\r\n",
      "Downloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pymupdf\r\n",
      "Successfully installed pymupdf-1.26.4\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51d711e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T10:55:35.850911Z",
     "iopub.status.busy": "2025-09-04T10:55:35.850114Z",
     "iopub.status.idle": "2025-09-04T10:55:37.605725Z",
     "shell.execute_reply": "2025-09-04T10:55:37.604699Z"
    },
    "papermill": {
     "duration": 1.761937,
     "end_time": "2025-09-04T10:55:37.607276",
     "exception": false,
     "start_time": "2025-09-04T10:55:35.845339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAINING DATA OVERVIEW ===\n",
      "Shape: (1066, 3)\n",
      "Rows: 1066, Columns: 3\n",
      "\n",
      "=== COLUMN NAMES ===\n",
      "['article_id', 'dataset_id', 'type']\n",
      "\n",
      "=== FIRST 5 ROWS ===\n",
      "               article_id                                 dataset_id     type\n",
      "0    10.1002_2017jc013030             https://doi.org/10.17882/49388  Primary\n",
      "1  10.1002_anie.201916483  https://doi.org/10.5517/ccdc.csd.cc1npvt0  Missing\n",
      "2  10.1002_anie.202005531  https://doi.org/10.5517/ccdc.csd.cc24wxqp  Missing\n",
      "3  10.1002_anie.202007717  https://doi.org/10.5517/ccdc.csd.cc24rrb0  Missing\n",
      "4  10.1002_chem.201902131  https://doi.org/10.5517/ccdc.csd.cc221dk3  Missing\n",
      "\n",
      "=== DATA TYPES ===\n",
      "article_id    object\n",
      "dataset_id    object\n",
      "type          object\n",
      "dtype: object\n",
      "\n",
      "=== MISSING VALUES ===\n",
      "article_id    0\n",
      "dataset_id    0\n",
      "type          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load training labels\n",
    "train_labels = pd.read_csv(\"/kaggle/input/make-data-count-finding-data-references/train_labels.csv\")\n",
    "\n",
    "print(\"=== TRAINING DATA OVERVIEW ===\")\n",
    "print(f\"Shape: {train_labels.shape}\")\n",
    "print(f\"Rows: {len(train_labels)}, Columns: {len(train_labels.columns)}\")\n",
    "print()\n",
    "\n",
    "print(\"=== COLUMN NAMES ===\")\n",
    "print(train_labels.columns.tolist())\n",
    "print()\n",
    "\n",
    "print(\"=== FIRST 5 ROWS ===\")\n",
    "print(train_labels.head())\n",
    "print()\n",
    "\n",
    "print(\"=== DATA TYPES ===\")\n",
    "print(train_labels.dtypes)\n",
    "print()\n",
    "\n",
    "print(\"=== MISSING VALUES ===\")\n",
    "print(train_labels.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cda7535",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T10:55:37.616855Z",
     "iopub.status.busy": "2025-09-04T10:55:37.616341Z",
     "iopub.status.idle": "2025-09-04T10:55:37.635184Z",
     "shell.execute_reply": "2025-09-04T10:55:37.634069Z"
    },
    "papermill": {
     "duration": 0.025349,
     "end_time": "2025-09-04T10:55:37.636621",
     "exception": false,
     "start_time": "2025-09-04T10:55:37.611272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CITATION TYPES ===\n",
      "type\n",
      "Secondary    449\n",
      "Missing      347\n",
      "Primary      270\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Type distribution:\n",
      "type\n",
      "Secondary    0.421201\n",
      "Missing      0.325516\n",
      "Primary      0.253283\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "=== DATASET ID PATTERNS ===\n",
      "Total unique datasets: 1066\n",
      "Most common datasets:\n",
      "dataset_id\n",
      "https://doi.org/10.17882/49388           1\n",
      "PRJNA167259                              1\n",
      "https://doi.org/10.5061/dryad.m4r46      1\n",
      "https://doi.org/10.5061/dryad.27m63      1\n",
      "https://doi.org/10.5061/dryad.27m63.1    1\n",
      "https://doi.org/10.5061/dryad.27m63.2    1\n",
      "https://doi.org/10.5061/dryad.kh186      1\n",
      "CP013147                                 1\n",
      "PRJNA10687                               1\n",
      "PRJNA16146                               1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== ARTICLE ID PATTERNS ===\n",
      "Total unique articles: 523\n",
      "Articles with most citations:\n",
      "article_id\n",
      "10.3390_v11060565               32\n",
      "10.1038_s41396-020-00885-8      31\n",
      "10.1128_spectrum.00422-24       29\n",
      "10.1371_journal.pone.0159387    27\n",
      "10.1371_journal.pone.0212669    25\n",
      "10.7717_peerj.10452             25\n",
      "10.1111_cas.12935               23\n",
      "10.1128_JVI.01717-21            22\n",
      "10.1371_journal.pcbi.1011828    22\n",
      "10.1038_s41598-020-59839-x      20\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Let's examine the target variables\n",
    "print(\"=== CITATION TYPES ===\")\n",
    "print(train_labels['type'].value_counts())\n",
    "print()\n",
    "print(\"Type distribution:\")\n",
    "print(train_labels['type'].value_counts(normalize=True))\n",
    "print()\n",
    "\n",
    "print(\"=== DATASET ID PATTERNS ===\")\n",
    "print(f\"Total unique datasets: {train_labels['dataset_id'].nunique()}\")\n",
    "print(\"Most common datasets:\")\n",
    "print(train_labels['dataset_id'].value_counts().head(10))\n",
    "print()\n",
    "\n",
    "print(\"=== ARTICLE ID PATTERNS ===\")\n",
    "print(f\"Total unique articles: {train_labels['article_id'].nunique()}\")\n",
    "print(\"Articles with most citations:\")\n",
    "print(train_labels['article_id'].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bfc8c56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T10:55:37.645813Z",
     "iopub.status.busy": "2025-09-04T10:55:37.645516Z",
     "iopub.status.idle": "2025-09-04T10:55:37.656518Z",
     "shell.execute_reply": "2025-09-04T10:55:37.655618Z"
    },
    "papermill": {
     "duration": 0.017152,
     "end_time": "2025-09-04T10:55:37.657908",
     "exception": false,
     "start_time": "2025-09-04T10:55:37.640756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATASET ID CATEGORIES ===\n",
      "Full URL                      :  668 (62.7%)\n",
      "Other                         :  303 (28.4%)\n",
      "ArrayExpress                  :   37 (3.5%)\n",
      "ChEMBL                        :   29 (2.7%)\n",
      "ENA (European Nucleotide Archive):   26 (2.4%)\n",
      "GEO (Gene Expression Omnibus) :    3 (0.3%)\n"
     ]
    }
   ],
   "source": [
    "# Let's categorize the types of dataset IDs we see\n",
    "def categorize_dataset_id(dataset_id):\n",
    "    \"\"\"Categorize dataset IDs by their pattern\"\"\"\n",
    "    if pd.isna(dataset_id):\n",
    "        return \"Missing\"\n",
    "    \n",
    "    dataset_id = str(dataset_id)\n",
    "    \n",
    "    if dataset_id.startswith('http'):\n",
    "        return \"Full URL\"\n",
    "    elif dataset_id.startswith('doi:') or 'doi.org' in dataset_id or dataset_id.startswith('10.'):\n",
    "        return \"DOI\"\n",
    "    elif dataset_id.startswith('GSE'):\n",
    "        return \"GEO (Gene Expression Omnibus)\"\n",
    "    elif dataset_id.startswith('E-'):\n",
    "        return \"ArrayExpress\"\n",
    "    elif dataset_id.startswith('PRJ'):\n",
    "        return \"ENA (European Nucleotide Archive)\"\n",
    "    elif dataset_id.startswith('PDB'):\n",
    "        return \"PDB (Protein Data Bank)\"\n",
    "    elif dataset_id.startswith('CHEMBL'):\n",
    "        return \"ChEMBL\"\n",
    "    elif 'zenodo' in dataset_id.lower():\n",
    "        return \"Zenodo\"\n",
    "    elif 'figshare' in dataset_id.lower():\n",
    "        return \"Figshare\"\n",
    "    elif 'dryad' in dataset_id.lower():\n",
    "        return \"Dryad\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "# Apply categorization\n",
    "train_labels['dataset_category'] = train_labels['dataset_id'].apply(categorize_dataset_id)\n",
    "\n",
    "print(\"=== DATASET ID CATEGORIES ===\")\n",
    "category_counts = train_labels['dataset_category'].value_counts()\n",
    "for category, count in category_counts.items():\n",
    "    print(f\"{category:30s}: {count:4d} ({count/len(train_labels)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f38fb8c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T10:55:37.666640Z",
     "iopub.status.busy": "2025-09-04T10:55:37.666351Z",
     "iopub.status.idle": "2025-09-04T10:55:37.675119Z",
     "shell.execute_reply": "2025-09-04T10:55:37.674191Z"
    },
    "papermill": {
     "duration": 0.014604,
     "end_time": "2025-09-04T10:55:37.676482",
     "exception": false,
     "start_time": "2025-09-04T10:55:37.661878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ARTICLE ID FORMATS ===\n",
      "Sample article IDs:\n",
      " 1. 10.1002_mp.14424\n",
      " 2. 10.1590_1809-6891v21e-43578\n",
      " 3. 10.1128_spectrum.00422-24\n",
      " 4. 10.7554_elife.62329\n",
      " 5. 10.1590_1679-78255326\n",
      " 6. 10.1371_journal.pone.0220399\n",
      " 7. 10.1186_s13007-019-0403-2\n",
      " 8. 10.1186_s12977-015-0204-2\n",
      " 9. 10.1029_2020jf005675\n",
      "10. 10.1128_spectrum.00422-24\n"
     ]
    }
   ],
   "source": [
    "# Let's also examine article IDs\n",
    "print(\"\\n=== ARTICLE ID FORMATS ===\")\n",
    "sample_articles = train_labels['article_id'].sample(10, random_state=42)\n",
    "print(\"Sample article IDs:\")\n",
    "for i, article in enumerate(sample_articles, 1):\n",
    "    print(f\"{i:2d}. {article}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a4731c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T10:55:37.685873Z",
     "iopub.status.busy": "2025-09-04T10:55:37.685563Z",
     "iopub.status.idle": "2025-09-04T10:55:37.699470Z",
     "shell.execute_reply": "2025-09-04T10:55:37.698602Z"
    },
    "papermill": {
     "duration": 0.020182,
     "end_time": "2025-09-04T10:55:37.700981",
     "exception": false,
     "start_time": "2025-09-04T10:55:37.680799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAINING DIRECTORY ===\n",
      "Total files in train directory: 2\n",
      "Sample files:\n",
      " 1. XML\n",
      " 2. PDF\n",
      "\n",
      "=== TEST DIRECTORY ===\n",
      "Total files in test directory: 2\n",
      "Sample files:\n",
      " 1. XML\n",
      " 2. PDF\n",
      "\n",
      "Train file extensions: {''}\n",
      "Test file extensions: {''}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "train_dir = \"/kaggle/input/make-data-count-finding-data-references/train\"\n",
    "test_dir = \"/kaggle/input/make-data-count-finding-data-references/test\"\n",
    "\n",
    "print(\"=== TRAINING DIRECTORY ===\")\n",
    "train_files = os.listdir(train_dir)\n",
    "print(f\"Total files in train directory: {len(train_files)}\")\n",
    "print(\"Sample files:\")\n",
    "for i, file in enumerate(train_files[:10], 1):\n",
    "    print(f\"{i:2d}. {file}\")\n",
    "\n",
    "print(\"\\n=== TEST DIRECTORY ===\")\n",
    "test_files = os.listdir(test_dir)\n",
    "print(f\"Total files in test directory: {len(test_files)}\")\n",
    "print(\"Sample files:\")\n",
    "for i, file in enumerate(test_files[:10], 1):\n",
    "    print(f\"{i:2d}. {file}\")\n",
    "\n",
    "# Check file extensions\n",
    "train_extensions = [os.path.splitext(f)[1] for f in train_files]\n",
    "test_extensions = [os.path.splitext(f)[1] for f in test_files]\n",
    "\n",
    "print(f\"\\nTrain file extensions: {set(train_extensions)}\")\n",
    "print(f\"Test file extensions: {set(test_extensions)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f86044b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T10:55:37.710724Z",
     "iopub.status.busy": "2025-09-04T10:55:37.710149Z",
     "iopub.status.idle": "2025-09-04T10:55:37.722236Z",
     "shell.execute_reply": "2025-09-04T10:55:37.721267Z"
    },
    "papermill": {
     "duration": 0.01841,
     "end_time": "2025-09-04T10:55:37.723778",
     "exception": false,
     "start_time": "2025-09-04T10:55:37.705368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CITATIONS PER ARTICLE ===\n",
      "Min citations per article: 1\n",
      "Max citations per article: 32\n",
      "Mean citations per article: 2.04\n",
      "Median citations per article: 1.00\n",
      "\n",
      "Articles with most citations:\n",
      "article_id\n",
      "10.3390_v11060565               32\n",
      "10.1038_s41396-020-00885-8      31\n",
      "10.1128_spectrum.00422-24       29\n",
      "10.1371_journal.pone.0159387    27\n",
      "10.1371_journal.pone.0212669    25\n",
      "10.7717_peerj.10452             25\n",
      "10.1111_cas.12935               23\n",
      "10.1128_JVI.01717-21            22\n",
      "10.1371_journal.pcbi.1011828    22\n",
      "10.1038_s41598-020-59839-x      20\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution of citations per article:\n",
      "count\n",
      "1     421\n",
      "2      52\n",
      "3      15\n",
      "4       7\n",
      "5       2\n",
      "6       1\n",
      "7       2\n",
      "8       1\n",
      "10      2\n",
      "11      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# How many citations per article?\n",
    "citations_per_article = train_labels['article_id'].value_counts()\n",
    "print(\"=== CITATIONS PER ARTICLE ===\")\n",
    "print(f\"Min citations per article: {citations_per_article.min()}\")\n",
    "print(f\"Max citations per article: {citations_per_article.max()}\")\n",
    "print(f\"Mean citations per article: {citations_per_article.mean():.2f}\")\n",
    "print(f\"Median citations per article: {citations_per_article.median():.2f}\")\n",
    "\n",
    "print(\"\\nArticles with most citations:\")\n",
    "print(citations_per_article.head(10))\n",
    "\n",
    "print(\"\\nDistribution of citations per article:\")\n",
    "print(citations_per_article.value_counts().sort_index().head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20e4ede8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T10:55:37.733435Z",
     "iopub.status.busy": "2025-09-04T10:55:37.733163Z",
     "iopub.status.idle": "2025-09-04T10:55:37.745972Z",
     "shell.execute_reply": "2025-09-04T10:55:37.745117Z"
    },
    "papermill": {
     "duration": 0.019204,
     "end_time": "2025-09-04T10:55:37.747399",
     "exception": false,
     "start_time": "2025-09-04T10:55:37.728195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATASET REUSE PATTERNS ===\n",
      "Datasets cited once: 1066\n",
      "Datasets cited multiple times: 0\n",
      "Most cited datasets:\n",
      "dataset_id\n",
      "https://doi.org/10.17882/49388           1\n",
      "PRJNA167259                              1\n",
      "https://doi.org/10.5061/dryad.m4r46      1\n",
      "https://doi.org/10.5061/dryad.27m63      1\n",
      "https://doi.org/10.5061/dryad.27m63.1    1\n",
      "https://doi.org/10.5061/dryad.27m63.2    1\n",
      "https://doi.org/10.5061/dryad.kh186      1\n",
      "CP013147                                 1\n",
      "PRJNA10687                               1\n",
      "PRJNA16146                               1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Datasets that appear with different types: 0\n"
     ]
    }
   ],
   "source": [
    "# How often is each dataset cited?\n",
    "dataset_citation_counts = train_labels['dataset_id'].value_counts()\n",
    "print(\"=== DATASET REUSE PATTERNS ===\")\n",
    "print(f\"Datasets cited once: {sum(dataset_citation_counts == 1)}\")\n",
    "print(f\"Datasets cited multiple times: {sum(dataset_citation_counts > 1)}\")\n",
    "print(f\"Most cited datasets:\")\n",
    "print(dataset_citation_counts.head(10))\n",
    "\n",
    "# Check if the same dataset can have different types in different papers\n",
    "dataset_type_combinations = train_labels.groupby('dataset_id')['type'].nunique()\n",
    "multi_type_datasets = dataset_type_combinations[dataset_type_combinations > 1]\n",
    "print(f\"\\nDatasets that appear with different types: {len(multi_type_datasets)}\")\n",
    "if len(multi_type_datasets) > 0:\n",
    "    print(\"Examples:\")\n",
    "    for dataset in multi_type_datasets.index[:5]:\n",
    "        types = train_labels[train_labels['dataset_id'] == dataset]['type'].unique()\n",
    "        print(f\"  {dataset}: {list(types)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9748ada5",
   "metadata": {
    "papermill": {
     "duration": 0.004077,
     "end_time": "2025-09-04T10:55:37.755722",
     "exception": false,
     "start_time": "2025-09-04T10:55:37.751645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Letâ€™s now examine a specific PDF to understand the content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53224c54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T10:55:37.766277Z",
     "iopub.status.busy": "2025-09-04T10:55:37.765524Z",
     "iopub.status.idle": "2025-09-04T10:55:38.179256Z",
     "shell.execute_reply": "2025-09-04T10:55:38.178186Z"
    },
    "papermill": {
     "duration": 0.420333,
     "end_time": "2025-09-04T10:55:38.181037",
     "exception": false,
     "start_time": "2025-09-04T10:55:37.760704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PDF CONTENT FOR 10.1002_2017jc013030 ===\n",
      "Number of pages: 22\n",
      "Total text length: 14559 characters\n",
      "\n",
      "First 1000 characters:\n",
      "==================================================\n",
      "RESEARCH ARTICLE\n",
      "10.1002/2017JC013030\n",
      "Assessing the Variability in the Relationship Between the\n",
      "Particulate Backscattering Coefficient and the Chlorophyll a\n",
      "Concentration From a Global Biogeochemical-Argo Database\n",
      "Marie Barbieux1\n",
      ", Julia Uitz1, Annick Bricaud1, Emanuele Organelli1,2\n",
      ", Antoine Poteau1\n",
      ",\n",
      "Catherine Schmechtig3\n",
      ", Bernard Gentili1, Grigor Obolensky4, Edouard Leymarie1\n",
      ",\n",
      "Christophe Penkercâ€™h1, Fabrizio Dâ€™Ortenzio1\n",
      ", and Herv\u0002e Claustre1\n",
      "1Sorbonne Universit\u0002es, UPMC Univ Paris 06, CNRS, Observatoire Oc\u0002eanologique de Villefranche, Laboratoire\n",
      "dâ€™Oc\u0002eanographie de Villefranche, Villefranche-sur-Mer, France, 2Plymouth Marine Laboratory, Prospect Place, The Hoe,\n",
      "Plymouth, United Kingdom, 3OSU Ecce Terra, UMS 3455, CNRS and Universit\u0002e Pierre et Marie Curie, Paris 6, Paris, France,\n",
      "4ERIC Euro-Argo, 29280 Plouzan\u0002e, France\n",
      "Abstract Characterizing phytoplankton distribution and dynamics in the worldâ€™s open oceans requires in\n",
      "situ observations over a broad range of space and time sca\n",
      "==================================================\n",
      "\n",
      "Known citations for this paper (1):\n",
      "  - https://doi.org/10.17882/49388 (Primary)\n",
      "\n",
      "============================================================\n",
      "=== PDF CONTENT FOR 10.3390_v11060565 ===\n",
      "Number of pages: 8\n",
      "Total text length: 10425 characters\n",
      "\n",
      "First 1000 characters:\n",
      "==================================================\n",
      "viruses\n",
      "Communication\n",
      "Isolation of a Novel Reassortant Highly Pathogenic\n",
      "Avian Inï¬‚uenza (H5N2) Virus in Egypt\n",
      "Naglaa M. Hagag 1, Ahmed M. Erfan 1\n",
      ", Mohamed El-Husseiny 1, Azhar G. Shalaby 1,\n",
      "Mohamed A. Saif 1, Maram M. Tawakol 1, Ahmed A. Nour 1, Abdullah A. Selim 1,\n",
      "Abdel-Satar Arafa 1, Mohamed K. Hassan 1, Wafaa M. M. Hassan 1, Hanan A. Fahmy 1,\n",
      "Essam Ibraheem 1, Mohamed Attia 2, Ali M. M. Abdelhakim 2, Momtaz A. Shahein 1 and\n",
      "Mahmoud M. Naguib 1,3,*\n",
      "1\n",
      "National Laboratory for Veterinary Quality Control on Poultry Production,\n",
      "Animal Health Research Institute, 7 Nadi El-Seid Street, 12618 Dokki, Cairo, Dokki-Giza, Egypt;\n",
      "naglaahagagahri@gmail.com (N.M.H.); Ahmed.erfan10000@gmail.com (A.M.E.);\n",
      "olivera_2006@yahoo.com (M.E.-H.); azhargaber0@gmail.com (A.G.S.);\n",
      "mohamed_saif85@hotmail.com (M.A.S.); maram_salah2020@yahoo.com (M.M.T.);\n",
      "mada_boky@yahoo.com (A.A.N.); abdullahselim@yahoo.com (A.A.S.); araby85@hotmail.com (A.-S.A.);\n",
      "mkahassan2020@gmail.com (M.K.H.); fooaaa@live.com (W.M.M.H.); dr\n",
      "==================================================\n",
      "\n",
      "Known citations for this paper (32):\n",
      "  - D10700 (Secondary)\n",
      "  - EPI1018205 (Secondary)\n",
      "  - EPI1018206 (Secondary)\n",
      "  - EPI1018207 (Secondary)\n",
      "  - EPI1018208 (Secondary)\n",
      "  - EPI1018210 (Secondary)\n",
      "  - EPI1018211 (Secondary)\n",
      "  - EPI1019551 (Secondary)\n",
      "  - EPI1019552 (Secondary)\n",
      "  - EPI1019553 (Secondary)\n",
      "  - EPI1019554 (Secondary)\n",
      "  - EPI1019555 (Secondary)\n",
      "  - EPI1019556 (Secondary)\n",
      "  - EPI1019558 (Secondary)\n",
      "  - EPI1104284 (Secondary)\n",
      "  - EPI1104285 (Secondary)\n",
      "  - EPI1104286 (Secondary)\n",
      "  - EPI1104288 (Secondary)\n",
      "  - EPI1183999 (Secondary)\n",
      "  - EPI1184004 (Secondary)\n",
      "  - EPI1184005 (Secondary)\n",
      "  - EPI1184014 (Secondary)\n",
      "  - EPI1387245 (Primary)\n",
      "  - EPI954552 (Secondary)\n",
      "  - EPI954553 (Secondary)\n",
      "  - EPI954554 (Secondary)\n",
      "  - EPI954555 (Secondary)\n",
      "  - EPI954556 (Secondary)\n",
      "  - EPI954557 (Secondary)\n",
      "  - EPI954559 (Secondary)\n",
      "  - KX000727 (Secondary)\n",
      "  - KX000734 (Secondary)\n"
     ]
    }
   ],
   "source": [
    "import pymupdf\n",
    "\n",
    "def examine_pdf_content(article_id):\n",
    "    \"\"\"Examine the content of a PDF file\"\"\"\n",
    "    pdf_path = f\"/kaggle/input/make-data-count-finding-data-references/train/PDF/{article_id}.pdf\"\n",
    "    \n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(f\"PDF not found: {pdf_path}\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        doc = pymupdf.open(pdf_path)\n",
    "        print(f\"=== PDF CONTENT FOR {article_id} ===\")\n",
    "        print(f\"Number of pages: {len(doc)}\")\n",
    "        \n",
    "        # Get text from first few pages\n",
    "        full_text = \"\"\n",
    "        for page_num in range(min(3, len(doc))):  # First 3 pages max\n",
    "            page = doc[page_num]\n",
    "            full_text += page.get_text()\n",
    "        \n",
    "        print(f\"Total text length: {len(full_text)} characters\")\n",
    "        print(\"\\nFirst 1000 characters:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(full_text[:1000])\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Look for citations in this paper\n",
    "        paper_citations = train_labels[train_labels['article_id'] == article_id]\n",
    "        print(f\"\\nKnown citations for this paper ({len(paper_citations)}):\")\n",
    "        for _, row in paper_citations.iterrows():\n",
    "            print(f\"  - {row['dataset_id']} ({row['type']})\")\n",
    "        \n",
    "        doc.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PDF {article_id}: {e}\")\n",
    "\n",
    "# Examine a sample article\n",
    "if len(train_labels) > 0:\n",
    "    sample_article = train_labels['article_id'].iloc[0]\n",
    "    examine_pdf_content(sample_article)\n",
    "    \n",
    "    # Examine another article with multiple citations\n",
    "    article_with_most_citations = train_labels['article_id'].value_counts().index[0]\n",
    "    if article_with_most_citations != sample_article:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        examine_pdf_content(article_with_most_citations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114f323f",
   "metadata": {
    "papermill": {
     "duration": 0.004146,
     "end_time": "2025-09-04T10:55:38.189763",
     "exception": false,
     "start_time": "2025-09-04T10:55:38.185617",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Letâ€™s also check the DOI formats and make sure we understand the submission requirements:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a5ae739",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T10:55:38.199716Z",
     "iopub.status.busy": "2025-09-04T10:55:38.199182Z",
     "iopub.status.idle": "2025-09-04T10:55:38.216483Z",
     "shell.execute_reply": "2025-09-04T10:55:38.215499Z"
    },
    "papermill": {
     "duration": 0.023949,
     "end_time": "2025-09-04T10:55:38.217960",
     "exception": false,
     "start_time": "2025-09-04T10:55:38.194011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DOI FORMAT ANALYSIS ===\n",
      "Total Full URLs: 668\n",
      "Total DOIs (within Full URLs): 668\n",
      "DOI format distribution:\n",
      "  https://doi.org/    :  668 (100.0%)\n",
      "  http://doi.org/     :    0 (0.0%)\n",
      "  doi:                :    0 (0.0%)\n",
      "  Other DOI format    :    0 (0.0%)\n",
      "\n",
      "Sample DOIs by format:\n",
      "  https://doi.org/:\n",
      "    https://doi.org/10.17882/49388\n",
      "    https://doi.org/10.5517/ccdc.csd.cc1npvt0\n",
      "    https://doi.org/10.5517/ccdc.csd.cc24wxqp\n"
     ]
    }
   ],
   "source": [
    "def analyze_doi_formats():\n",
    "    \"\"\"Analyze DOI formats in the dataset\"\"\"\n",
    "    # Filter for Full URL category since DOIs are URLs\n",
    "    full_urls = train_labels[train_labels['dataset_category'] == 'Full URL']['dataset_id']\n",
    "    \n",
    "    # Further filter for actual DOIs within Full URLs\n",
    "    dois = full_urls[full_urls.str.contains('doi.org', case=False, na=False)]\n",
    "    \n",
    "    print(\"=== DOI FORMAT ANALYSIS ===\")\n",
    "    print(f\"Total Full URLs: {len(full_urls)}\")\n",
    "    print(f\"Total DOIs (within Full URLs): {len(dois)}\")\n",
    "    \n",
    "    if len(dois) == 0:\n",
    "        print(\"No DOIs found in the dataset.\")\n",
    "        return\n",
    "    \n",
    "    # Check different DOI formats\n",
    "    doi_formats = {\n",
    "        'https://doi.org/': sum(dois.str.startswith('https://doi.org/', na=False)),\n",
    "        'http://doi.org/': sum(dois.str.startswith('http://doi.org/', na=False)),\n",
    "        'doi:': sum(dois.str.startswith('doi:', na=False)),\n",
    "        'Other DOI format': len(dois) - sum(dois.str.startswith(('https://doi.org/', 'http://doi.org/', 'doi:'), na=False))\n",
    "    }\n",
    "    \n",
    "    print(\"DOI format distribution:\")\n",
    "    for format_name, count in doi_formats.items():\n",
    "        if len(dois) > 0:  # Prevent division by zero\n",
    "            percentage = count/len(dois)*100\n",
    "            print(f\"  {format_name:20s}: {count:4d} ({percentage:.1f}%)\")\n",
    "        else:\n",
    "            print(f\"  {format_name:20s}: {count:4d} (0.0%)\")\n",
    "    \n",
    "    print(\"\\nSample DOIs by format:\")\n",
    "    for format_name in doi_formats:\n",
    "        if doi_formats[format_name] > 0:\n",
    "            # Get sample DOIs of this format\n",
    "            if format_name == 'https://doi.org/':\n",
    "                sample = dois[dois.str.startswith('https://doi.org/', na=False)].head(3)\n",
    "            elif format_name == 'http://doi.org/':\n",
    "                sample = dois[dois.str.startswith('http://doi.org/', na=False)].head(3)\n",
    "            elif format_name == 'doi:':\n",
    "                sample = dois[dois.str.startswith('doi:', na=False)].head(3)\n",
    "            else:  # Other DOI format\n",
    "                mask = ~dois.str.startswith(('https://doi.org/', 'http://doi.org/', 'doi:'), na=False)\n",
    "                sample = dois[mask].head(3)\n",
    "            \n",
    "            print(f\"  {format_name}:\")\n",
    "            for doi in sample:\n",
    "                print(f\"    {doi}\")\n",
    "\n",
    "analyze_doi_formats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f44d4b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T10:55:38.228638Z",
     "iopub.status.busy": "2025-09-04T10:55:38.228005Z",
     "iopub.status.idle": "2025-09-04T10:55:38.242103Z",
     "shell.execute_reply": "2025-09-04T10:55:38.241201Z"
    },
    "papermill": {
     "duration": 0.021201,
     "end_time": "2025-09-04T10:55:38.243802",
     "exception": false,
     "start_time": "2025-09-04T10:55:38.222601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DETAILED DATASET ID ANALYSIS ===\n",
      "\n",
      "Total 'Other' category datasets: 303\n",
      "Breakdown of 'Other' category:\n",
      "  EPI (GISAID)   :  64 (21.1%)\n",
      "  CP (GenBank)   :   3 (1.0%)\n",
      "  KX (GenBank)   :   2 (0.7%)\n",
      "  D (Accession)  :   1 (0.3%)\n",
      "\n",
      "Sample 'Other' datasets:\n",
      "   1. 5VA1\n",
      "   2. IPR000884\n",
      "   3. IPR001124\n",
      "   4. IPR001577\n",
      "   5. IPR002477\n",
      "   6. IPR002889\n",
      "   7. IPR004007\n",
      "   8. IPR004302\n",
      "   9. IPR004785\n",
      "  10. IPR004911\n"
     ]
    }
   ],
   "source": [
    "def detailed_dataset_analysis():\n",
    "    \"\"\"Detailed analysis of dataset ID patterns\"\"\"\n",
    "    print(\"=== DETAILED DATASET ID ANALYSIS ===\")\n",
    "    \n",
    "    # Look at the 'Other' category more closely\n",
    "    other_datasets = train_labels[train_labels['dataset_category'] == 'Other']['dataset_id']\n",
    "    print(f\"\\nTotal 'Other' category datasets: {len(other_datasets)}\")\n",
    "    \n",
    "    # Try to categorize the 'Other' datasets further\n",
    "    epi_count = sum(other_datasets.str.startswith('EPI', na=False))\n",
    "    prj_count = sum(other_datasets.str.startswith('PRJ', na=False))\n",
    "    pdb_count = sum(other_datasets.str.startswith('PDB', na=False))\n",
    "    chembl_count = sum(other_datasets.str.startswith('CHEMBL', na=False))\n",
    "    gse_count = sum(other_datasets.str.startswith('GSE', na=False))\n",
    "    cp_count = sum(other_datasets.str.startswith('CP', na=False))\n",
    "    kx_count = sum(other_datasets.str.startswith('KX', na=False))\n",
    "    d_count = sum(other_datasets.str.startswith('D', na=False))\n",
    "    \n",
    "    print(\"Breakdown of 'Other' category:\")\n",
    "    other_breakdown = {\n",
    "        'EPI (GISAID)': epi_count,\n",
    "        'PRJ (ENA)': prj_count,\n",
    "        'PDB': pdb_count,\n",
    "        'CHEMBL': chembl_count,\n",
    "        'GSE (GEO)': gse_count,\n",
    "        'CP (GenBank)': cp_count,\n",
    "        'KX (GenBank)': kx_count,\n",
    "        'D (Accession)': d_count\n",
    "    }\n",
    "    \n",
    "    for category, count in other_breakdown.items():\n",
    "        if count > 0:\n",
    "            print(f\"  {category:15s}: {count:3d} ({count/len(other_datasets)*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nSample 'Other' datasets:\")\n",
    "    for i, dataset in enumerate(other_datasets.head(10), 1):\n",
    "        print(f\"  {i:2d}. {dataset}\")\n",
    "\n",
    "detailed_dataset_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7ea85c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T10:55:38.262151Z",
     "iopub.status.busy": "2025-09-04T10:55:38.261873Z",
     "iopub.status.idle": "2025-09-04T10:55:38.272642Z",
     "shell.execute_reply": "2025-09-04T10:55:38.271521Z"
    },
    "papermill": {
     "duration": 0.021288,
     "end_time": "2025-09-04T10:55:38.274145",
     "exception": false,
     "start_time": "2025-09-04T10:55:38.252857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANALYSIS OF 'MISSING' TYPE ENTRIES ===\n",
      "Number of 'Missing' entries: 347\n",
      "\n",
      "Dataset IDs for 'Missing' entries:\n",
      "   1. https://doi.org/10.5517/ccdc.csd.cc1npvt0\n",
      "   2. https://doi.org/10.5517/ccdc.csd.cc24wxqp\n",
      "   3. https://doi.org/10.5517/ccdc.csd.cc24rrb0\n",
      "   4. https://doi.org/10.5517/ccdc.csd.cc221dk3\n",
      "   5. https://doi.org/10.5517/ccdc.csd.cc22c4yk\n",
      "   6. https://doi.org/10.5517/ccdc.csd.cc24cjxz\n",
      "   7. https://doi.org/10.5517/ccdc.csd.cc24nsk5\n",
      "   8. https://doi.org/10.5517/ccdc.csd.cc24nsqb\n",
      "   9. https://doi.org/10.5517/ccdc.csd.cc24d93z\n",
      "  10. https://doi.org/10.5517/ccdc.csd.cc250wsw\n",
      "\n",
      "Categories of 'Missing' entries:\n",
      "dataset_id\n",
      "Full URL    343\n",
      "Other         4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def analyze_missing_type():\n",
    "    \"\"\"Analyze the 'Missing' type entries\"\"\"\n",
    "    print(\"=== ANALYSIS OF 'MISSING' TYPE ENTRIES ===\")\n",
    "    missing_entries = train_labels[train_labels['type'] == 'Missing']\n",
    "    \n",
    "    print(f\"Number of 'Missing' entries: {len(missing_entries)}\")\n",
    "    \n",
    "    print(\"\\nDataset IDs for 'Missing' entries:\")\n",
    "    for i, (_, row) in enumerate(missing_entries.head(10).iterrows(), 1):\n",
    "        print(f\"  {i:2d}. {row['dataset_id']}\")\n",
    "    \n",
    "    # Check if these have a pattern\n",
    "    missing_datasets = missing_entries['dataset_id']\n",
    "    missing_categories = missing_datasets.apply(categorize_dataset_id)\n",
    "    print(\"\\nCategories of 'Missing' entries:\")\n",
    "    print(missing_categories.value_counts())\n",
    "\n",
    "analyze_missing_type()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57677bdc",
   "metadata": {
    "papermill": {
     "duration": 0.0059,
     "end_time": "2025-09-04T10:55:38.289294",
     "exception": false,
     "start_time": "2025-09-04T10:55:38.283394",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"font-family: Arial, sans-serif; background: linear-gradient(135deg, #0f5132, #145a44); color: #fff; padding: 20px; border-radius: 8px;\">\n",
    "  <h1 style=\"text-align: center; margin-top: 0;\">ðŸ“Š  Data Summary</h1>\n",
    "\n",
    "  <div style=\"background: rgba(255,255,255,0.1); padding: 15px; border-radius: 6px; margin-bottom: 15px;\">\n",
    "    <h2>ðŸ“¦ Dataset Overview</h2>\n",
    "    <ul>\n",
    "      <li><b>Shape:</b> 1066 rows Ã— 3 columns</li>\n",
    "      <li><b>Columns:</b> <code>article_id</code>, <code>dataset_id</code>, <code>type</code></li>\n",
    "      <li><b>Missing Values:</b> None</li>\n",
    "    </ul>\n",
    "  </div>\n",
    "\n",
    "  <div style=\"background: rgba(255,255,255,0.1); padding: 15px; border-radius: 6px; margin-bottom: 15px;\">\n",
    "    <h2>ðŸ§¾ Citation Types</h2>\n",
    "    <ul>\n",
    "      <li>Secondary: <b>449</b> (42.1%)</li>\n",
    "      <li>Missing: <b>347</b> (32.6%)</li>\n",
    "      <li>Primary: <b>270</b> (25.3%)</li>\n",
    "    </ul>\n",
    "  </div>\n",
    "\n",
    "  <div style=\"background: rgba(255,255,255,0.1); padding: 15px; border-radius: 6px; margin-bottom: 15px;\">\n",
    "    <h2>ðŸ”— Dataset ID Categories</h2>\n",
    "    <ul>\n",
    "      <li>Full URL: <b>668</b> (62.7%) â€” all in <code>https://doi.org/</code> format</li>\n",
    "      <li>Other: <b>303</b> (28.4%)</li>\n",
    "      <li>ArrayExpress: 37 (3.5%)</li>\n",
    "      <li>ChEMBL: 29 (2.7%)</li>\n",
    "      <li>ENA: 26 (2.4%)</li>\n",
    "      <li>GEO: 3 (0.3%)</li>\n",
    "    </ul>\n",
    "    <p><b>Other category breakdown:</b> EPI/GISAIDâ€¯64, CP/GenBankâ€¯3, KX/GenBankâ€¯2, D/Accessionâ€¯1</p>\n",
    "  </div>\n",
    "\n",
    "  <div style=\"background: rgba(255,255,255,0.1); padding: 15px; border-radius: 6px; margin-bottom: 15px;\">\n",
    "    <h2>ðŸ“„ Article Stats</h2>\n",
    "    <ul>\n",
    "      <li>Total unique articles: <b>523</b></li>\n",
    "      <li>Citations per article â€” Min: 1, Max: 32, Mean: 2.04, Median: 1</li>\n",
    "      <li>Most cited: <code>10.3390_v11060565</code> (32 citations)</li>\n",
    "    </ul>\n",
    "  </div>\n",
    "\n",
    "  <div style=\"background: rgba(255,255,255,0.1); padding: 15px; border-radius: 6px;\">\n",
    "    <h2>ðŸ“‚ Directory Info</h2>\n",
    "    <ul>\n",
    "      <li>Train dir files: 2 (XML + PDF, no extensions detected)</li>\n",
    "      <li>Test dir files: 2 (XML + PDF, no extensions detected)</li>\n",
    "    </ul>\n",
    "  </div>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13015230,
     "sourceId": 82370,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.711626,
   "end_time": "2025-09-04T10:55:41.384980",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-04T10:55:23.673354",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
