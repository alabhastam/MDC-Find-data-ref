{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9d45b85",
   "metadata": {
    "papermill": {
     "duration": 0.004317,
     "end_time": "2025-09-04T10:55:29.023726",
     "exception": false,
     "start_time": "2025-09-04T10:55:29.019409",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# EDA and undertanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d33ee22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T10:55:29.031789Z",
     "iopub.status.busy": "2025-09-04T10:55:29.031468Z",
     "iopub.status.idle": "2025-09-04T10:55:35.839365Z",
     "shell.execute_reply": "2025-09-04T10:55:35.838418Z"
    },
    "papermill": {
     "duration": 6.813946,
     "end_time": "2025-09-04T10:55:35.841178",
     "exception": false,
     "start_time": "2025-09-04T10:55:29.027232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf\r\n",
      "  Downloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\r\n",
      "Downloading pymupdf-1.26.4-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pymupdf\r\n",
      "Successfully installed pymupdf-1.26.4\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51d711e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T10:55:35.850911Z",
     "iopub.status.busy": "2025-09-04T10:55:35.850114Z",
     "iopub.status.idle": "2025-09-04T10:55:37.605725Z",
     "shell.execute_reply": "2025-09-04T10:55:37.604699Z"
    },
    "papermill": {
     "duration": 1.761937,
     "end_time": "2025-09-04T10:55:37.607276",
     "exception": false,
     "start_time": "2025-09-04T10:55:35.845339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAINING DATA OVERVIEW ===\n",
      "Shape: (1066, 3)\n",
      "Rows: 1066, Columns: 3\n",
      "\n",
      "=== COLUMN NAMES ===\n",
      "['article_id', 'dataset_id', 'type']\n",
      "\n",
      "=== FIRST 5 ROWS ===\n",
      "               article_id                                 dataset_id     type\n",
      "0    10.1002_2017jc013030             https://doi.org/10.17882/49388  Primary\n",
      "1  10.1002_anie.201916483  https://doi.org/10.5517/ccdc.csd.cc1npvt0  Missing\n",
      "2  10.1002_anie.202005531  https://doi.org/10.5517/ccdc.csd.cc24wxqp  Missing\n",
      "3  10.1002_anie.202007717  https://doi.org/10.5517/ccdc.csd.cc24rrb0  Missing\n",
      "4  10.1002_chem.201902131  https://doi.org/10.5517/ccdc.csd.cc221dk3  Missing\n",
      "\n",
      "=== DATA TYPES ===\n",
      "article_id    object\n",
      "dataset_id    object\n",
      "type          object\n",
      "dtype: object\n",
      "\n",
      "=== MISSING VALUES ===\n",
      "article_id    0\n",
      "dataset_id    0\n",
      "type          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load training labels\n",
    "train_labels = pd.read_csv(\"/kaggle/input/make-data-count-finding-data-references/train_labels.csv\")\n",
    "\n",
    "print(\"=== TRAINING DATA OVERVIEW ===\")\n",
    "print(f\"Shape: {train_labels.shape}\")\n",
    "print(f\"Rows: {len(train_labels)}, Columns: {len(train_labels.columns)}\")\n",
    "print()\n",
    "\n",
    "print(\"=== COLUMN NAMES ===\")\n",
    "print(train_labels.columns.tolist())\n",
    "print()\n",
    "\n",
    "print(\"=== FIRST 5 ROWS ===\")\n",
    "print(train_labels.head())\n",
    "print()\n",
    "\n",
    "print(\"=== DATA TYPES ===\")\n",
    "print(train_labels.dtypes)\n",
    "print()\n",
    "\n",
    "print(\"=== MISSING VALUES ===\")\n",
    "print(train_labels.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cda7535",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T10:55:37.616855Z",
     "iopub.status.busy": "2025-09-04T10:55:37.616341Z",
     "iopub.status.idle": "2025-09-04T10:55:37.635184Z",
     "shell.execute_reply": "2025-09-04T10:55:37.634069Z"
    },
    "papermill": {
     "duration": 0.025349,
     "end_time": "2025-09-04T10:55:37.636621",
     "exception": false,
     "start_time": "2025-09-04T10:55:37.611272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CITATION TYPES ===\n",
      "type\n",
      "Secondary    449\n",
      "Missing      347\n",
      "Primary      270\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Type distribution:\n",
      "type\n",
      "Secondary    0.421201\n",
      "Missing      0.325516\n",
      "Primary      0.253283\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "=== DATASET ID PATTERNS ===\n",
      "Total unique datasets: 1066\n",
      "Most common datasets:\n",
      "dataset_id\n",
      "https://doi.org/10.17882/49388           1\n",
      "PRJNA167259                              1\n",
      "https://doi.org/10.5061/dryad.m4r46      1\n",
      "https://doi.org/10.5061/dryad.27m63      1\n",
      "https://doi.org/10.5061/dryad.27m63.1    1\n",
      "https://doi.org/10.5061/dryad.27m63.2    1\n",
      "https://doi.org/10.5061/dryad.kh186      1\n",
      "CP013147                                 1\n",
      "PRJNA10687                               1\n",
      "PRJNA16146                               1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== ARTICLE ID PATTERNS ===\n",
      "Total unique articles: 523\n",
      "Articles with most citations:\n",
      "article_id\n",
      "10.3390_v11060565               32\n",
      "10.1038_s41396-020-00885-8      31\n",
      "10.1128_spectrum.00422-24       29\n",
      "10.1371_journal.pone.0159387    27\n",
      "10.1371_journal.pone.0212669    25\n",
      "10.7717_peerj.10452             25\n",
      "10.1111_cas.12935               23\n",
      "10.1128_JVI.01717-21            22\n",
      "10.1371_journal.pcbi.1011828    22\n",
      "10.1038_s41598-020-59839-x      20\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Let's examine the target variables\n",
    "print(\"=== CITATION TYPES ===\")\n",
    "print(train_labels['type'].value_counts())\n",
    "print()\n",
    "print(\"Type distribution:\")\n",
    "print(train_labels['type'].value_counts(normalize=True))\n",
    "print()\n",
    "\n",
    "print(\"=== DATASET ID PATTERNS ===\")\n",
    "print(f\"Total unique datasets: {train_labels['dataset_id'].nunique()}\")\n",
    "print(\"Most common datasets:\")\n",
    "print(train_labels['dataset_id'].value_counts().head(10))\n",
    "print()\n",
    "\n",
    "print(\"=== ARTICLE ID PATTERNS ===\")\n",
    "print(f\"Total unique articles: {train_labels['article_id'].nunique()}\")\n",
    "print(\"Articles with most citations:\")\n",
    "print(train_labels['article_id'].value_counts().head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bfc8c56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T10:55:37.645813Z",
     "iopub.status.busy": "2025-09-04T10:55:37.645516Z",
     "iopub.status.idle": "2025-09-04T10:55:37.656518Z",
     "shell.execute_reply": "2025-09-04T10:55:37.655618Z"
    },
    "papermill": {
     "duration": 0.017152,
     "end_time": "2025-09-04T10:55:37.657908",
     "exception": false,
     "start_time": "2025-09-04T10:55:37.640756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATASET ID CATEGORIES ===\n",
      "Full URL                      :  668 (62.7%)\n",
      "Other                         :  303 (28.4%)\n",
      "ArrayExpress                  :   37 (3.5%)\n",
      "ChEMBL                        :   29 (2.7%)\n",
      "ENA (European Nucleotide Archive):   26 (2.4%)\n",
      "GEO (Gene Expression Omnibus) :    3 (0.3%)\n"
     ]
    }
   ],
   "source": [
    "# Let's categorize the types of dataset IDs we see\n",
    "def categorize_dataset_id(dataset_id):\n",
    "    \"\"\"Categorize dataset IDs by their pattern\"\"\"\n",
    "    if pd.isna(dataset_id):\n",
    "        return \"Missing\"\n",
    "    \n",
    "    dataset_id = str(dataset_id)\n",
    "    \n",
    "    if dataset_id.startswith('http'):\n",
    "        return \"Full URL\"\n",
    "    elif dataset_id.startswith('doi:') or 'doi.org' in dataset_id or dataset_id.startswith('10.'):\n",
    "        return \"DOI\"\n",
    "    elif dataset_id.startswith('GSE'):\n",
    "        return \"GEO (Gene Expression Omnibus)\"\n",
    "    elif dataset_id.startswith('E-'):\n",
    "        return \"ArrayExpress\"\n",
    "    elif dataset_id.startswith('PRJ'):\n",
    "        return \"ENA (European Nucleotide Archive)\"\n",
    "    elif dataset_id.startswith('PDB'):\n",
    "        return \"PDB (Protein Data Bank)\"\n",
    "    elif dataset_id.startswith('CHEMBL'):\n",
    "        return \"ChEMBL\"\n",
    "    elif 'zenodo' in dataset_id.lower():\n",
    "        return \"Zenodo\"\n",
    "    elif 'figshare' in dataset_id.lower():\n",
    "        return \"Figshare\"\n",
    "    elif 'dryad' in dataset_id.lower():\n",
    "        return \"Dryad\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "# Apply categorization\n",
    "train_labels['dataset_category'] = train_labels['dataset_id'].apply(categorize_dataset_id)\n",
    "\n",
    "print(\"=== DATASET ID CATEGORIES ===\")\n",
    "category_counts = train_labels['dataset_category'].value_counts()\n",
    "for category, count in category_counts.items():\n",
    "    print(f\"{category:30s}: {count:4d} ({count/len(train_labels)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f38fb8c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T10:55:37.666640Z",
     "iopub.status.busy": "2025-09-04T10:55:37.666351Z",
     "iopub.status.idle": "2025-09-04T10:55:37.675119Z",
     "shell.execute_reply": "2025-09-04T10:55:37.674191Z"
    },
    "papermill": {
     "duration": 0.014604,
     "end_time": "2025-09-04T10:55:37.676482",
     "exception": false,
     "start_time": "2025-09-04T10:55:37.661878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ARTICLE ID FORMATS ===\n",
      "Sample article IDs:\n",
      " 1. 10.1002_mp.14424\n",
      " 2. 10.1590_1809-6891v21e-43578\n",
      " 3. 10.1128_spectrum.00422-24\n",
      " 4. 10.7554_elife.62329\n",
      " 5. 10.1590_1679-78255326\n",
      " 6. 10.1371_journal.pone.0220399\n",
      " 7. 10.1186_s13007-019-0403-2\n",
      " 8. 10.1186_s12977-015-0204-2\n",
      " 9. 10.1029_2020jf005675\n",
      "10. 10.1128_spectrum.00422-24\n"
     ]
    }
   ],
   "source": [
    "# Let's also examine article IDs\n",
    "print(\"\\n=== ARTICLE ID FORMATS ===\")\n",
    "sample_articles = train_labels['article_id'].sample(10, random_state=42)\n",
    "print(\"Sample article IDs:\")\n",
    "for i, article in enumerate(sample_articles, 1):\n",
    "    print(f\"{i:2d}. {article}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a4731c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T10:55:37.685873Z",
     "iopub.status.busy": "2025-09-04T10:55:37.685563Z",
     "iopub.status.idle": "2025-09-04T10:55:37.699470Z",
     "shell.execute_reply": "2025-09-04T10:55:37.698602Z"
    },
    "papermill": {
     "duration": 0.020182,
     "end_time": "2025-09-04T10:55:37.700981",
     "exception": false,
     "start_time": "2025-09-04T10:55:37.680799",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRAINING DIRECTORY ===\n",
      "Total files in train directory: 2\n",
      "Sample files:\n",
      " 1. XML\n",
      " 2. PDF\n",
      "\n",
      "=== TEST DIRECTORY ===\n",
      "Total files in test directory: 2\n",
      "Sample files:\n",
      " 1. XML\n",
      " 2. PDF\n",
      "\n",
      "Train file extensions: {''}\n",
      "Test file extensions: {''}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "train_dir = \"/kaggle/input/make-data-count-finding-data-references/train\"\n",
    "test_dir = \"/kaggle/input/make-data-count-finding-data-references/test\"\n",
    "\n",
    "print(\"=== TRAINING DIRECTORY ===\")\n",
    "train_files = os.listdir(train_dir)\n",
    "print(f\"Total files in train directory: {len(train_files)}\")\n",
    "print(\"Sample files:\")\n",
    "for i, file in enumerate(train_files[:10], 1):\n",
    "    print(f\"{i:2d}. {file}\")\n",
    "\n",
    "print(\"\\n=== TEST DIRECTORY ===\")\n",
    "test_files = os.listdir(test_dir)\n",
    "print(f\"Total files in test directory: {len(test_files)}\")\n",
    "print(\"Sample files:\")\n",
    "for i, file in enumerate(test_files[:10], 1):\n",
    "    print(f\"{i:2d}. {file}\")\n",
    "\n",
    "# Check file extensions\n",
    "train_extensions = [os.path.splitext(f)[1] for f in train_files]\n",
    "test_extensions = [os.path.splitext(f)[1] for f in test_files]\n",
    "\n",
    "print(f\"\\nTrain file extensions: {set(train_extensions)}\")\n",
    "print(f\"Test file extensions: {set(test_extensions)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f86044b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T10:55:37.710724Z",
     "iopub.status.busy": "2025-09-04T10:55:37.710149Z",
     "iopub.status.idle": "2025-09-04T10:55:37.722236Z",
     "shell.execute_reply": "2025-09-04T10:55:37.721267Z"
    },
    "papermill": {
     "duration": 0.01841,
     "end_time": "2025-09-04T10:55:37.723778",
     "exception": false,
     "start_time": "2025-09-04T10:55:37.705368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CITATIONS PER ARTICLE ===\n",
      "Min citations per article: 1\n",
      "Max citations per article: 32\n",
      "Mean citations per article: 2.04\n",
      "Median citations per article: 1.00\n",
      "\n",
      "Articles with most citations:\n",
      "article_id\n",
      "10.3390_v11060565               32\n",
      "10.1038_s41396-020-00885-8      31\n",
      "10.1128_spectrum.00422-24       29\n",
      "10.1371_journal.pone.0159387    27\n",
      "10.1371_journal.pone.0212669    25\n",
      "10.7717_peerj.10452             25\n",
      "10.1111_cas.12935               23\n",
      "10.1128_JVI.01717-21            22\n",
      "10.1371_journal.pcbi.1011828    22\n",
      "10.1038_s41598-020-59839-x      20\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution of citations per article:\n",
      "count\n",
      "1     421\n",
      "2      52\n",
      "3      15\n",
      "4       7\n",
      "5       2\n",
      "6       1\n",
      "7       2\n",
      "8       1\n",
      "10      2\n",
      "11      1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# How many citations per article?\n",
    "citations_per_article = train_labels['article_id'].value_counts()\n",
    "print(\"=== CITATIONS PER ARTICLE ===\")\n",
    "print(f\"Min citations per article: {citations_per_article.min()}\")\n",
    "print(f\"Max citations per article: {citations_per_article.max()}\")\n",
    "print(f\"Mean citations per article: {citations_per_article.mean():.2f}\")\n",
    "print(f\"Median citations per article: {citations_per_article.median():.2f}\")\n",
    "\n",
    "print(\"\\nArticles with most citations:\")\n",
    "print(citations_per_article.head(10))\n",
    "\n",
    "print(\"\\nDistribution of citations per article:\")\n",
    "print(citations_per_article.value_counts().sort_index().head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20e4ede8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T10:55:37.733435Z",
     "iopub.status.busy": "2025-09-04T10:55:37.733163Z",
     "iopub.status.idle": "2025-09-04T10:55:37.745972Z",
     "shell.execute_reply": "2025-09-04T10:55:37.745117Z"
    },
    "papermill": {
     "duration": 0.019204,
     "end_time": "2025-09-04T10:55:37.747399",
     "exception": false,
     "start_time": "2025-09-04T10:55:37.728195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DATASET REUSE PATTERNS ===\n",
      "Datasets cited once: 1066\n",
      "Datasets cited multiple times: 0\n",
      "Most cited datasets:\n",
      "dataset_id\n",
      "https://doi.org/10.17882/49388           1\n",
      "PRJNA167259                              1\n",
      "https://doi.org/10.5061/dryad.m4r46      1\n",
      "https://doi.org/10.5061/dryad.27m63      1\n",
      "https://doi.org/10.5061/dryad.27m63.1    1\n",
      "https://doi.org/10.5061/dryad.27m63.2    1\n",
      "https://doi.org/10.5061/dryad.kh186      1\n",
      "CP013147                                 1\n",
      "PRJNA10687                               1\n",
      "PRJNA16146                               1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Datasets that appear with different types: 0\n"
     ]
    }
   ],
   "source": [
    "# How often is each dataset cited?\n",
    "dataset_citation_counts = train_labels['dataset_id'].value_counts()\n",
    "print(\"=== DATASET REUSE PATTERNS ===\")\n",
    "print(f\"Datasets cited once: {sum(dataset_citation_counts == 1)}\")\n",
    "print(f\"Datasets cited multiple times: {sum(dataset_citation_counts > 1)}\")\n",
    "print(f\"Most cited datasets:\")\n",
    "print(dataset_citation_counts.head(10))\n",
    "\n",
    "# Check if the same dataset can have different types in different papers\n",
    "dataset_type_combinations = train_labels.groupby('dataset_id')['type'].nunique()\n",
    "multi_type_datasets = dataset_type_combinations[dataset_type_combinations > 1]\n",
    "print(f\"\\nDatasets that appear with different types: {len(multi_type_datasets)}\")\n",
    "if len(multi_type_datasets) > 0:\n",
    "    print(\"Examples:\")\n",
    "    for dataset in multi_type_datasets.index[:5]:\n",
    "        types = train_labels[train_labels['dataset_id'] == dataset]['type'].unique()\n",
    "        print(f\"  {dataset}: {list(types)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9748ada5",
   "metadata": {
    "papermill": {
     "duration": 0.004077,
     "end_time": "2025-09-04T10:55:37.755722",
     "exception": false,
     "start_time": "2025-09-04T10:55:37.751645",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let’s now examine a specific PDF to understand the content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53224c54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T10:55:37.766277Z",
     "iopub.status.busy": "2025-09-04T10:55:37.765524Z",
     "iopub.status.idle": "2025-09-04T10:55:38.179256Z",
     "shell.execute_reply": "2025-09-04T10:55:38.178186Z"
    },
    "papermill": {
     "duration": 0.420333,
     "end_time": "2025-09-04T10:55:38.181037",
     "exception": false,
     "start_time": "2025-09-04T10:55:37.760704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== PDF CONTENT FOR 10.1002_2017jc013030 ===\n",
      "Number of pages: 22\n",
      "Total text length: 14559 characters\n",
      "\n",
      "First 1000 characters:\n",
      "==================================================\n",
      "RESEARCH ARTICLE\n",
      "10.1002/2017JC013030\n",
      "Assessing the Variability in the Relationship Between the\n",
      "Particulate Backscattering Coefficient and the Chlorophyll a\n",
      "Concentration From a Global Biogeochemical-Argo Database\n",
      "Marie Barbieux1\n",
      ", Julia Uitz1, Annick Bricaud1, Emanuele Organelli1,2\n",
      ", Antoine Poteau1\n",
      ",\n",
      "Catherine Schmechtig3\n",
      ", Bernard Gentili1, Grigor Obolensky4, Edouard Leymarie1\n",
      ",\n",
      "Christophe Penkerc’h1, Fabrizio D’Ortenzio1\n",
      ", and Herv\u0002e Claustre1\n",
      "1Sorbonne Universit\u0002es, UPMC Univ Paris 06, CNRS, Observatoire Oc\u0002eanologique de Villefranche, Laboratoire\n",
      "d’Oc\u0002eanographie de Villefranche, Villefranche-sur-Mer, France, 2Plymouth Marine Laboratory, Prospect Place, The Hoe,\n",
      "Plymouth, United Kingdom, 3OSU Ecce Terra, UMS 3455, CNRS and Universit\u0002e Pierre et Marie Curie, Paris 6, Paris, France,\n",
      "4ERIC Euro-Argo, 29280 Plouzan\u0002e, France\n",
      "Abstract Characterizing phytoplankton distribution and dynamics in the world’s open oceans requires in\n",
      "situ observations over a broad range of space and time sca\n",
      "==================================================\n",
      "\n",
      "Known citations for this paper (1):\n",
      "  - https://doi.org/10.17882/49388 (Primary)\n",
      "\n",
      "============================================================\n",
      "=== PDF CONTENT FOR 10.3390_v11060565 ===\n",
      "Number of pages: 8\n",
      "Total text length: 10425 characters\n",
      "\n",
      "First 1000 characters:\n",
      "==================================================\n",
      "viruses\n",
      "Communication\n",
      "Isolation of a Novel Reassortant Highly Pathogenic\n",
      "Avian Inﬂuenza (H5N2) Virus in Egypt\n",
      "Naglaa M. Hagag 1, Ahmed M. Erfan 1\n",
      ", Mohamed El-Husseiny 1, Azhar G. Shalaby 1,\n",
      "Mohamed A. Saif 1, Maram M. Tawakol 1, Ahmed A. Nour 1, Abdullah A. Selim 1,\n",
      "Abdel-Satar Arafa 1, Mohamed K. Hassan 1, Wafaa M. M. Hassan 1, Hanan A. Fahmy 1,\n",
      "Essam Ibraheem 1, Mohamed Attia 2, Ali M. M. Abdelhakim 2, Momtaz A. Shahein 1 and\n",
      "Mahmoud M. Naguib 1,3,*\n",
      "1\n",
      "National Laboratory for Veterinary Quality Control on Poultry Production,\n",
      "Animal Health Research Institute, 7 Nadi El-Seid Street, 12618 Dokki, Cairo, Dokki-Giza, Egypt;\n",
      "naglaahagagahri@gmail.com (N.M.H.); Ahmed.erfan10000@gmail.com (A.M.E.);\n",
      "olivera_2006@yahoo.com (M.E.-H.); azhargaber0@gmail.com (A.G.S.);\n",
      "mohamed_saif85@hotmail.com (M.A.S.); maram_salah2020@yahoo.com (M.M.T.);\n",
      "mada_boky@yahoo.com (A.A.N.); abdullahselim@yahoo.com (A.A.S.); araby85@hotmail.com (A.-S.A.);\n",
      "mkahassan2020@gmail.com (M.K.H.); fooaaa@live.com (W.M.M.H.); dr\n",
      "==================================================\n",
      "\n",
      "Known citations for this paper (32):\n",
      "  - D10700 (Secondary)\n",
      "  - EPI1018205 (Secondary)\n",
      "  - EPI1018206 (Secondary)\n",
      "  - EPI1018207 (Secondary)\n",
      "  - EPI1018208 (Secondary)\n",
      "  - EPI1018210 (Secondary)\n",
      "  - EPI1018211 (Secondary)\n",
      "  - EPI1019551 (Secondary)\n",
      "  - EPI1019552 (Secondary)\n",
      "  - EPI1019553 (Secondary)\n",
      "  - EPI1019554 (Secondary)\n",
      "  - EPI1019555 (Secondary)\n",
      "  - EPI1019556 (Secondary)\n",
      "  - EPI1019558 (Secondary)\n",
      "  - EPI1104284 (Secondary)\n",
      "  - EPI1104285 (Secondary)\n",
      "  - EPI1104286 (Secondary)\n",
      "  - EPI1104288 (Secondary)\n",
      "  - EPI1183999 (Secondary)\n",
      "  - EPI1184004 (Secondary)\n",
      "  - EPI1184005 (Secondary)\n",
      "  - EPI1184014 (Secondary)\n",
      "  - EPI1387245 (Primary)\n",
      "  - EPI954552 (Secondary)\n",
      "  - EPI954553 (Secondary)\n",
      "  - EPI954554 (Secondary)\n",
      "  - EPI954555 (Secondary)\n",
      "  - EPI954556 (Secondary)\n",
      "  - EPI954557 (Secondary)\n",
      "  - EPI954559 (Secondary)\n",
      "  - KX000727 (Secondary)\n",
      "  - KX000734 (Secondary)\n"
     ]
    }
   ],
   "source": [
    "import pymupdf\n",
    "\n",
    "def examine_pdf_content(article_id):\n",
    "    \"\"\"Examine the content of a PDF file\"\"\"\n",
    "    pdf_path = f\"/kaggle/input/make-data-count-finding-data-references/train/PDF/{article_id}.pdf\"\n",
    "    \n",
    "    if not os.path.exists(pdf_path):\n",
    "        print(f\"PDF not found: {pdf_path}\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        doc = pymupdf.open(pdf_path)\n",
    "        print(f\"=== PDF CONTENT FOR {article_id} ===\")\n",
    "        print(f\"Number of pages: {len(doc)}\")\n",
    "        \n",
    "        # Get text from first few pages\n",
    "        full_text = \"\"\n",
    "        for page_num in range(min(3, len(doc))):  # First 3 pages max\n",
    "            page = doc[page_num]\n",
    "            full_text += page.get_text()\n",
    "        \n",
    "        print(f\"Total text length: {len(full_text)} characters\")\n",
    "        print(\"\\nFirst 1000 characters:\")\n",
    "        print(\"=\" * 50)\n",
    "        print(full_text[:1000])\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        # Look for citations in this paper\n",
    "        paper_citations = train_labels[train_labels['article_id'] == article_id]\n",
    "        print(f\"\\nKnown citations for this paper ({len(paper_citations)}):\")\n",
    "        for _, row in paper_citations.iterrows():\n",
    "            print(f\"  - {row['dataset_id']} ({row['type']})\")\n",
    "        \n",
    "        doc.close()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error reading PDF {article_id}: {e}\")\n",
    "\n",
    "# Examine a sample article\n",
    "if len(train_labels) > 0:\n",
    "    sample_article = train_labels['article_id'].iloc[0]\n",
    "    examine_pdf_content(sample_article)\n",
    "    \n",
    "    # Examine another article with multiple citations\n",
    "    article_with_most_citations = train_labels['article_id'].value_counts().index[0]\n",
    "    if article_with_most_citations != sample_article:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        examine_pdf_content(article_with_most_citations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114f323f",
   "metadata": {
    "papermill": {
     "duration": 0.004146,
     "end_time": "2025-09-04T10:55:38.189763",
     "exception": false,
     "start_time": "2025-09-04T10:55:38.185617",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let’s also check the DOI formats and make sure we understand the submission requirements:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a5ae739",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T10:55:38.199716Z",
     "iopub.status.busy": "2025-09-04T10:55:38.199182Z",
     "iopub.status.idle": "2025-09-04T10:55:38.216483Z",
     "shell.execute_reply": "2025-09-04T10:55:38.215499Z"
    },
    "papermill": {
     "duration": 0.023949,
     "end_time": "2025-09-04T10:55:38.217960",
     "exception": false,
     "start_time": "2025-09-04T10:55:38.194011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DOI FORMAT ANALYSIS ===\n",
      "Total Full URLs: 668\n",
      "Total DOIs (within Full URLs): 668\n",
      "DOI format distribution:\n",
      "  https://doi.org/    :  668 (100.0%)\n",
      "  http://doi.org/     :    0 (0.0%)\n",
      "  doi:                :    0 (0.0%)\n",
      "  Other DOI format    :    0 (0.0%)\n",
      "\n",
      "Sample DOIs by format:\n",
      "  https://doi.org/:\n",
      "    https://doi.org/10.17882/49388\n",
      "    https://doi.org/10.5517/ccdc.csd.cc1npvt0\n",
      "    https://doi.org/10.5517/ccdc.csd.cc24wxqp\n"
     ]
    }
   ],
   "source": [
    "def analyze_doi_formats():\n",
    "    \"\"\"Analyze DOI formats in the dataset\"\"\"\n",
    "    # Filter for Full URL category since DOIs are URLs\n",
    "    full_urls = train_labels[train_labels['dataset_category'] == 'Full URL']['dataset_id']\n",
    "    \n",
    "    # Further filter for actual DOIs within Full URLs\n",
    "    dois = full_urls[full_urls.str.contains('doi.org', case=False, na=False)]\n",
    "    \n",
    "    print(\"=== DOI FORMAT ANALYSIS ===\")\n",
    "    print(f\"Total Full URLs: {len(full_urls)}\")\n",
    "    print(f\"Total DOIs (within Full URLs): {len(dois)}\")\n",
    "    \n",
    "    if len(dois) == 0:\n",
    "        print(\"No DOIs found in the dataset.\")\n",
    "        return\n",
    "    \n",
    "    # Check different DOI formats\n",
    "    doi_formats = {\n",
    "        'https://doi.org/': sum(dois.str.startswith('https://doi.org/', na=False)),\n",
    "        'http://doi.org/': sum(dois.str.startswith('http://doi.org/', na=False)),\n",
    "        'doi:': sum(dois.str.startswith('doi:', na=False)),\n",
    "        'Other DOI format': len(dois) - sum(dois.str.startswith(('https://doi.org/', 'http://doi.org/', 'doi:'), na=False))\n",
    "    }\n",
    "    \n",
    "    print(\"DOI format distribution:\")\n",
    "    for format_name, count in doi_formats.items():\n",
    "        if len(dois) > 0:  # Prevent division by zero\n",
    "            percentage = count/len(dois)*100\n",
    "            print(f\"  {format_name:20s}: {count:4d} ({percentage:.1f}%)\")\n",
    "        else:\n",
    "            print(f\"  {format_name:20s}: {count:4d} (0.0%)\")\n",
    "    \n",
    "    print(\"\\nSample DOIs by format:\")\n",
    "    for format_name in doi_formats:\n",
    "        if doi_formats[format_name] > 0:\n",
    "            # Get sample DOIs of this format\n",
    "            if format_name == 'https://doi.org/':\n",
    "                sample = dois[dois.str.startswith('https://doi.org/', na=False)].head(3)\n",
    "            elif format_name == 'http://doi.org/':\n",
    "                sample = dois[dois.str.startswith('http://doi.org/', na=False)].head(3)\n",
    "            elif format_name == 'doi:':\n",
    "                sample = dois[dois.str.startswith('doi:', na=False)].head(3)\n",
    "            else:  # Other DOI format\n",
    "                mask = ~dois.str.startswith(('https://doi.org/', 'http://doi.org/', 'doi:'), na=False)\n",
    "                sample = dois[mask].head(3)\n",
    "            \n",
    "            print(f\"  {format_name}:\")\n",
    "            for doi in sample:\n",
    "                print(f\"    {doi}\")\n",
    "\n",
    "analyze_doi_formats()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f44d4b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T10:55:38.228638Z",
     "iopub.status.busy": "2025-09-04T10:55:38.228005Z",
     "iopub.status.idle": "2025-09-04T10:55:38.242103Z",
     "shell.execute_reply": "2025-09-04T10:55:38.241201Z"
    },
    "papermill": {
     "duration": 0.021201,
     "end_time": "2025-09-04T10:55:38.243802",
     "exception": false,
     "start_time": "2025-09-04T10:55:38.222601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== DETAILED DATASET ID ANALYSIS ===\n",
      "\n",
      "Total 'Other' category datasets: 303\n",
      "Breakdown of 'Other' category:\n",
      "  EPI (GISAID)   :  64 (21.1%)\n",
      "  CP (GenBank)   :   3 (1.0%)\n",
      "  KX (GenBank)   :   2 (0.7%)\n",
      "  D (Accession)  :   1 (0.3%)\n",
      "\n",
      "Sample 'Other' datasets:\n",
      "   1. 5VA1\n",
      "   2. IPR000884\n",
      "   3. IPR001124\n",
      "   4. IPR001577\n",
      "   5. IPR002477\n",
      "   6. IPR002889\n",
      "   7. IPR004007\n",
      "   8. IPR004302\n",
      "   9. IPR004785\n",
      "  10. IPR004911\n"
     ]
    }
   ],
   "source": [
    "def detailed_dataset_analysis():\n",
    "    \"\"\"Detailed analysis of dataset ID patterns\"\"\"\n",
    "    print(\"=== DETAILED DATASET ID ANALYSIS ===\")\n",
    "    \n",
    "    # Look at the 'Other' category more closely\n",
    "    other_datasets = train_labels[train_labels['dataset_category'] == 'Other']['dataset_id']\n",
    "    print(f\"\\nTotal 'Other' category datasets: {len(other_datasets)}\")\n",
    "    \n",
    "    # Try to categorize the 'Other' datasets further\n",
    "    epi_count = sum(other_datasets.str.startswith('EPI', na=False))\n",
    "    prj_count = sum(other_datasets.str.startswith('PRJ', na=False))\n",
    "    pdb_count = sum(other_datasets.str.startswith('PDB', na=False))\n",
    "    chembl_count = sum(other_datasets.str.startswith('CHEMBL', na=False))\n",
    "    gse_count = sum(other_datasets.str.startswith('GSE', na=False))\n",
    "    cp_count = sum(other_datasets.str.startswith('CP', na=False))\n",
    "    kx_count = sum(other_datasets.str.startswith('KX', na=False))\n",
    "    d_count = sum(other_datasets.str.startswith('D', na=False))\n",
    "    \n",
    "    print(\"Breakdown of 'Other' category:\")\n",
    "    other_breakdown = {\n",
    "        'EPI (GISAID)': epi_count,\n",
    "        'PRJ (ENA)': prj_count,\n",
    "        'PDB': pdb_count,\n",
    "        'CHEMBL': chembl_count,\n",
    "        'GSE (GEO)': gse_count,\n",
    "        'CP (GenBank)': cp_count,\n",
    "        'KX (GenBank)': kx_count,\n",
    "        'D (Accession)': d_count\n",
    "    }\n",
    "    \n",
    "    for category, count in other_breakdown.items():\n",
    "        if count > 0:\n",
    "            print(f\"  {category:15s}: {count:3d} ({count/len(other_datasets)*100:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nSample 'Other' datasets:\")\n",
    "    for i, dataset in enumerate(other_datasets.head(10), 1):\n",
    "        print(f\"  {i:2d}. {dataset}\")\n",
    "\n",
    "detailed_dataset_analysis()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7ea85c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T10:55:38.262151Z",
     "iopub.status.busy": "2025-09-04T10:55:38.261873Z",
     "iopub.status.idle": "2025-09-04T10:55:38.272642Z",
     "shell.execute_reply": "2025-09-04T10:55:38.271521Z"
    },
    "papermill": {
     "duration": 0.021288,
     "end_time": "2025-09-04T10:55:38.274145",
     "exception": false,
     "start_time": "2025-09-04T10:55:38.252857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANALYSIS OF 'MISSING' TYPE ENTRIES ===\n",
      "Number of 'Missing' entries: 347\n",
      "\n",
      "Dataset IDs for 'Missing' entries:\n",
      "   1. https://doi.org/10.5517/ccdc.csd.cc1npvt0\n",
      "   2. https://doi.org/10.5517/ccdc.csd.cc24wxqp\n",
      "   3. https://doi.org/10.5517/ccdc.csd.cc24rrb0\n",
      "   4. https://doi.org/10.5517/ccdc.csd.cc221dk3\n",
      "   5. https://doi.org/10.5517/ccdc.csd.cc22c4yk\n",
      "   6. https://doi.org/10.5517/ccdc.csd.cc24cjxz\n",
      "   7. https://doi.org/10.5517/ccdc.csd.cc24nsk5\n",
      "   8. https://doi.org/10.5517/ccdc.csd.cc24nsqb\n",
      "   9. https://doi.org/10.5517/ccdc.csd.cc24d93z\n",
      "  10. https://doi.org/10.5517/ccdc.csd.cc250wsw\n",
      "\n",
      "Categories of 'Missing' entries:\n",
      "dataset_id\n",
      "Full URL    343\n",
      "Other         4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def analyze_missing_type():\n",
    "    \"\"\"Analyze the 'Missing' type entries\"\"\"\n",
    "    print(\"=== ANALYSIS OF 'MISSING' TYPE ENTRIES ===\")\n",
    "    missing_entries = train_labels[train_labels['type'] == 'Missing']\n",
    "    \n",
    "    print(f\"Number of 'Missing' entries: {len(missing_entries)}\")\n",
    "    \n",
    "    print(\"\\nDataset IDs for 'Missing' entries:\")\n",
    "    for i, (_, row) in enumerate(missing_entries.head(10).iterrows(), 1):\n",
    "        print(f\"  {i:2d}. {row['dataset_id']}\")\n",
    "    \n",
    "    # Check if these have a pattern\n",
    "    missing_datasets = missing_entries['dataset_id']\n",
    "    missing_categories = missing_datasets.apply(categorize_dataset_id)\n",
    "    print(\"\\nCategories of 'Missing' entries:\")\n",
    "    print(missing_categories.value_counts())\n",
    "\n",
    "analyze_missing_type()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57677bdc",
   "metadata": {
    "papermill": {
     "duration": 0.0059,
     "end_time": "2025-09-04T10:55:38.289294",
     "exception": false,
     "start_time": "2025-09-04T10:55:38.283394",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<div style=\"font-family: Arial, sans-serif; background: linear-gradient(135deg, #0f5132, #145a44); color: #fff; padding: 20px; border-radius: 8px;\">\n",
    "  <h1 style=\"text-align: center; margin-top: 0;\">📊  Data Summary</h1>\n",
    "\n",
    "  <div style=\"background: rgba(255,255,255,0.1); padding: 15px; border-radius: 6px; margin-bottom: 15px;\">\n",
    "    <h2>📦 Dataset Overview</h2>\n",
    "    <ul>\n",
    "      <li><b>Shape:</b> 1066 rows × 3 columns</li>\n",
    "      <li><b>Columns:</b> <code>article_id</code>, <code>dataset_id</code>, <code>type</code></li>\n",
    "      <li><b>Missing Values:</b> None</li>\n",
    "    </ul>\n",
    "  </div>\n",
    "\n",
    "  <div style=\"background: rgba(255,255,255,0.1); padding: 15px; border-radius: 6px; margin-bottom: 15px;\">\n",
    "    <h2>🧾 Citation Types</h2>\n",
    "    <ul>\n",
    "      <li>Secondary: <b>449</b> (42.1%)</li>\n",
    "      <li>Missing: <b>347</b> (32.6%)</li>\n",
    "      <li>Primary: <b>270</b> (25.3%)</li>\n",
    "    </ul>\n",
    "  </div>\n",
    "\n",
    "  <div style=\"background: rgba(255,255,255,0.1); padding: 15px; border-radius: 6px; margin-bottom: 15px;\">\n",
    "    <h2>🔗 Dataset ID Categories</h2>\n",
    "    <ul>\n",
    "      <li>Full URL: <b>668</b> (62.7%) — all in <code>https://doi.org/</code> format</li>\n",
    "      <li>Other: <b>303</b> (28.4%)</li>\n",
    "      <li>ArrayExpress: 37 (3.5%)</li>\n",
    "      <li>ChEMBL: 29 (2.7%)</li>\n",
    "      <li>ENA: 26 (2.4%)</li>\n",
    "      <li>GEO: 3 (0.3%)</li>\n",
    "    </ul>\n",
    "    <p><b>Other category breakdown:</b> EPI/GISAID 64, CP/GenBank 3, KX/GenBank 2, D/Accession 1</p>\n",
    "  </div>\n",
    "\n",
    "  <div style=\"background: rgba(255,255,255,0.1); padding: 15px; border-radius: 6px; margin-bottom: 15px;\">\n",
    "    <h2>📄 Article Stats</h2>\n",
    "    <ul>\n",
    "      <li>Total unique articles: <b>523</b></li>\n",
    "      <li>Citations per article — Min: 1, Max: 32, Mean: 2.04, Median: 1</li>\n",
    "      <li>Most cited: <code>10.3390_v11060565</code> (32 citations)</li>\n",
    "    </ul>\n",
    "  </div>\n",
    "\n",
    "  <div style=\"background: rgba(255,255,255,0.1); padding: 15px; border-radius: 6px;\">\n",
    "    <h2>📂 Directory Info</h2>\n",
    "    <ul>\n",
    "      <li>Train dir files: 2 (XML + PDF, no extensions detected)</li>\n",
    "      <li>Test dir files: 2 (XML + PDF, no extensions detected)</li>\n",
    "    </ul>\n",
    "  </div>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 13015230,
     "sourceId": 82370,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.711626,
   "end_time": "2025-09-04T10:55:41.384980",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-09-04T10:55:23.673354",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
